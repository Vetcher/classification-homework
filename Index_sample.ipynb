{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import bisect\n",
    "\n",
    "import pymorphy2\n",
    "\n",
    "from collections import defaultdict, namedtuple, Counter\n",
    "from itertools import chain\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "DocEntry = namedtuple('DocEntry', ['doc_id', 'positions'])\n",
    "\n",
    "class Parser:\n",
    "    def __init__(self):\n",
    "        self.analyzer = pymorphy2.MorphAnalyzer()    \n",
    "    \n",
    "    def parse_text(self, text):\n",
    "        words = (word for word in re.split('\\W+', text) if len(word) > 0)\n",
    "        norm_form = (self.analyzer.normal_forms(word)[0] for word in words)\n",
    "    \n",
    "        return list(norm_form)\n",
    "\n",
    "\n",
    "class InvertedIndex:    \n",
    "    def __init__(self):\n",
    "        self.parser = Parser()\n",
    "        self.dict = defaultdict(list)\n",
    "        self.texts = dict()\n",
    "        \n",
    "    def add_document(self, doc_id, text):\n",
    "        self.texts[doc_id] = text\n",
    "        \n",
    "        words = self.parser.parse_text(text)\n",
    "        \n",
    "        word_to_entry = defaultdict(lambda: [])\n",
    "        \n",
    "        for pos, word in enumerate(words):\n",
    "            doc_entry = word_to_entry[word]\n",
    "            doc_entry.append(pos)\n",
    "        \n",
    "        for word, positions in word_to_entry.items():\n",
    "            postings = self.dict[word]\n",
    "            entry = DocEntry(doc_id, positions)\n",
    "            \n",
    "            i = bisect.bisect_left(postings, entry)\n",
    "            postings.insert(i, entry)\n",
    "\n",
    "    def get_postings(self, word):\n",
    "        return self.dict[word]    \n",
    "    \n",
    "    def merge(self, other_index):\n",
    "        self.texts.update(other_index.texts)\n",
    "        \n",
    "        # Task: calc complexity and impore merging  \n",
    "        for word, postings in other_index.dict.items():\n",
    "            my_postings = self.dict[word]            \n",
    "            self.dict[word] = sorted(chain(my_postings, postings))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Queue\n",
    "import zipfile\n",
    "import codecs\n",
    "\n",
    "def index_worker(in_queue, out_queue):\n",
    "    index = InvertedIndex()    \n",
    "      \n",
    "    while True:\n",
    "        data = in_queue.get()\n",
    "        \n",
    "        if data is None:\n",
    "            break\n",
    "            \n",
    "        split = data.split('\\t')\n",
    "        if len(split) == 2:\n",
    "            doc_id, text = split\n",
    "            index.add_document(doc_id, text)\n",
    "    \n",
    "    out_queue.put(index)\n",
    "\n",
    "    \n",
    "def index_multiproc():\n",
    "    num_workers = 3\n",
    "\n",
    "    in_queue = Queue(maxsize=100)\n",
    "    out_queue = Queue()\n",
    "\n",
    "    index = InvertedIndex()\n",
    "\n",
    "    workers = []\n",
    "    for _ in range(num_workers):\n",
    "        worker = Process(target=index_worker, args=(in_queue, out_queue))\n",
    "        worker.start()\n",
    "\n",
    "        workers.append(worker)\n",
    "\n",
    "    with zipfile.ZipFile('data/texts.zip') as zf:\n",
    "        with zf.open('texts.txt', 'r') as f:\n",
    "            for i, line in tqdm_notebook(zip(range(500), codecs.iterdecode(f, 'utf-8'))):  \n",
    "                in_queue.put(line)\n",
    "\n",
    "    for _ in range(num_workers):\n",
    "        in_queue.put(None)\n",
    "\n",
    "    for worker in workers:\n",
    "        index.merge(out_queue.get())   \n",
    "        \n",
    "    return index\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    index = index_multiproc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
